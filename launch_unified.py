#!/usr/bin/env python3
"""
Unified Job Launcher - Auto-discovers templates and generates job scripts for all HPC facilities

Usage:
    python launch_unified.py job=my_job train_config=hiera auto_submit=false

Features:
    - Auto-discovers all templates in hydra_config/templates/ 
    - Generates job scripts for each facility: <job>.<facility>.<scheduler>
    - Supports SLURM (sbatch) and LSF (bsub) schedulers
    - Future-proof: just add new template files for new facilities
"""

import os
import sys
import glob
import yaml
from pathlib import Path

import hydra
from omegaconf import OmegaConf, DictConfig
from jinja2 import Environment, FileSystemLoader


def discover_templates(template_dir="hydra_config/templates"):
    """Auto-discover all template files and return facility info"""
    template_files = glob.glob(f"{template_dir}/*.*")
    facilities = []

    for template_path in template_files:
        template_file = os.path.basename(template_path)
        # Extract facility name and scheduler from filename
        # e.g., "s3df.sbatch" -> facility="s3df", scheduler="sbatch"
        name_parts = template_file.split('.')
        if len(name_parts) >= 2:
            facility = name_parts[0]
            scheduler = name_parts[1]
            facilities.append({
                'facility': facility,
                'scheduler': scheduler, 
                'template_path': template_path,
                'template_file': template_file
            })

    return facilities


def load_scheduler_config(facility, config_dir="hydra_config/scheduler_configs"):
    """Load facility-specific scheduler configuration"""
    config_path = f"{config_dir}/{facility}.yaml"
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    else:
        print(f"Warning: No scheduler config found for {facility} at {config_path}")
        return {}


def load_resource_config(resource_name, config_dir="hydra_config/resource_configs"):
    """Load resource-specific configuration (compute requirements, etc.)"""
    config_path = f"{config_dir}/{resource_name}.yaml"
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    else:
        print(f"Warning: No resource config found for {resource_name} at {config_path}")
        return {}


def render_job_script(template_path, config_data):
    """Render job script using Jinja2 template"""
    template_dir = os.path.dirname(template_path)
    template_file = os.path.basename(template_path)

    env = Environment(loader=FileSystemLoader(template_dir))
    template = env.get_template(template_file)
    return template.render(**config_data)


@hydra.main(config_path="hydra_config", config_name="base", version_base=None)
def main(cfg: DictConfig):
    """Main launcher that generates job scripts for all discovered facilities"""

    print("üöÄ Unified Job Launcher")
    print("=" * 50)

    # ----------------------------------------------------------------------- #
    #  Setup shared values
    # ----------------------------------------------------------------------- #
    job = cfg.job

    # Create output directories
    os.makedirs("experiments/yaml", exist_ok=True) 
    os.makedirs("experiments/jobs", exist_ok=True)

    # Generate shared YAML config
    yaml_filename = f"{job}.yaml"
    yaml_path = f"experiments/yaml/{yaml_filename}"

    print(f"üìù Generating shared YAML config: {yaml_path}")
    with open(yaml_path, 'w') as f:
        f.write(OmegaConf.to_yaml(cfg.train_config))
        f.write("\n")
        f.write(f"# Generated by: python {' '.join(sys.argv)}\n")

    # ----------------------------------------------------------------------- #
    #  Auto-discover templates and generate job scripts  
    # ----------------------------------------------------------------------- #
    facilities = discover_templates()

    if not facilities:
        print("‚ùå No templates found in hydra_config/templates/")
        print("   Expected files like: s3df.sbatch, nersc.sbatch, summit.bsub")
        return

    print(f"üîç Discovered {len(facilities)} facilities:")
    for facility_info in facilities:
        print(f"   - {facility_info['facility']}.{facility_info['scheduler']}")
    print()

    generated_scripts = []

    for facility_info in facilities:
        facility = facility_info['facility']
        scheduler = facility_info['scheduler']
        template_path = facility_info['template_path']

        print(f"üèóÔ∏è  Generating {facility} job script...")

        # Load facility-specific scheduler config
        scheduler_config = load_scheduler_config(facility)

        # Load resource config if specified
        resource_name = 'base'  # default
        if hasattr(cfg, 'resource_configs') and hasattr(cfg.resource_configs, '_name'):
            resource_name = cfg.resource_configs._name
        elif hasattr(cfg, 'resource_config') and hasattr(cfg.resource_config, '_name'):
            resource_name = cfg.resource_config._name  # backward compatibility
        resource_config = load_resource_config(resource_name)

        # Start with resource config as base, then overlay scheduler config
        merged_config = {}
        merged_config.update(resource_config)
        merged_config.update(scheduler_config)

        # Merge with any existing scheduler_config from hydra
        if hasattr(cfg, f'{scheduler}_config'):
            hydra_config = OmegaConf.to_container(getattr(cfg, f'{scheduler}_config'))
            merged_config.update(hydra_config)

        # Merge with resource_configs from hydra if specified  
        if hasattr(cfg, 'resource_configs') and isinstance(cfg.resource_configs, DictConfig):
            resource_hydra_config = OmegaConf.to_container(cfg.resource_configs)
            merged_config.update(resource_hydra_config)
        elif hasattr(cfg, 'resource_config') and isinstance(cfg.resource_config, DictConfig):
            # Backward compatibility with old naming
            resource_hydra_config = OmegaConf.to_container(cfg.resource_config)
            merged_config.update(resource_hydra_config)

        # Override with job-specific values (these take priority)
        merged_config.update({
            'job': job,
            'yaml_config': yaml_path,
            'trainer': cfg.get('trainer', merged_config.get('trainer', 'train_hiera_seg.py'))
        })

        scheduler_config = merged_config

        # Render job script
        try:
            rendered_script = render_job_script(template_path, scheduler_config)

            # Save job script with facility naming convention
            job_filename = f"{job}.{facility}.{scheduler}"
            job_path = f"experiments/jobs/{job_filename}"

            with open(job_path, 'w') as f:
                f.write(rendered_script)
                f.write("\n")
                f.write(f"# Generated by: python {' '.join(sys.argv)}\n")

            generated_scripts.append(job_path)
            print(f"   ‚úÖ {job_path}")

        except Exception as e:
            print(f"   ‚ùå Failed to generate {facility} script: {e}")

    # ----------------------------------------------------------------------- #
    #  Summary and submission
    # ----------------------------------------------------------------------- #
    print("\n" + "=" * 50)
    print(f"üì¶ Generated {len(generated_scripts)} job scripts:")
    for script in generated_scripts:
        print(f"   {script}")

    print(f"\nüìÑ Shared config: {yaml_path}")

    # Handle auto-submission
    if cfg.get('auto_submit', False):
        target_facility = cfg.get('target_facility', None)
        if target_facility:
            # Submit only target facility
            target_scripts = [s for s in generated_scripts if f".{target_facility}." in s]
            if target_scripts:
                script = target_scripts[0]
                if 'sbatch' in script:
                    cmd = f"sbatch {script}"
                elif 'bsub' in script:
                    cmd = f"bsub {script}"
                else:
                    print(f"‚ùå Unknown scheduler type for {script}")
                    return

                print(f"üöÄ Auto-submitting: {cmd}")
                os.system(cmd)
            else:
                print(f"‚ùå No scripts found for target facility: {target_facility}")
        else:
            print("‚ùå auto_submit=true requires target_facility to be specified")
            print("   Available facilities:", [f['facility'] for f in facilities])
    else:
        print("\nüí° To submit a job, run:")
        for script in generated_scripts:
            if 'sbatch' in script:
                print(f"   sbatch {script}")
            elif 'bsub' in script:
                print(f"   bsub {script}")

    # ----------------------------------------------------------------------- #
    #  Preemptive checkpoint metadata cleanup
    # ----------------------------------------------------------------------- #
    dir_preempt = 'preempt'
    file_preempt = f'{job}.dat'
    path_preempt = os.path.join(dir_preempt, file_preempt)

    if cfg.get('skip_preempt', False):
        try:
            os.remove(path_preempt)
            print(f"üóëÔ∏è  Removed preemptive checkpoint: {path_preempt}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not remove preemptive checkpoint: {e}")

    if os.path.exists(path_preempt):
        if cfg.train_config.checkpoint.get('path_chkpt_prev') is not None:
            try:
                os.remove(path_preempt)
                print(f"üóëÔ∏è  Removed preemptive checkpoint (user specified path_chkpt_prev): {path_preempt}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not remove preemptive checkpoint: {e}")


if __name__ == "__main__":
    main()
