{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2070dda-63b5-4eb2-b1a5-9bfa0a49afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ConvNextV2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16e83b1-010f-42fe-b4af-cd84ce0bd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4b34338-8cf3-4754-a0c9-7fcfd22a7db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ConvNextV2Model.from_pretrained(\"facebook/convnextv2-atto-1k-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3de5569c-d45a-49d5-b72c-39830c5aebd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3874 M pamameters.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum(p.numel() for p in model.parameters())/1e6} M pamameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2359138-176d-4e31-b452-99af57cf8da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7a39943-4477-4315-92bc-6edd62528847",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.config.to_dict()\n",
    "if 'id2label' in config:\n",
    "    del config['id2label']\n",
    "if 'label2id' in config:\n",
    "    del config['label2id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35acf781-2b9e-4876-b354-7b05518afaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return_dict': True,\n",
       " 'output_hidden_states': False,\n",
       " 'output_attentions': False,\n",
       " 'torchscript': False,\n",
       " 'torch_dtype': 'float32',\n",
       " 'use_bfloat16': False,\n",
       " 'tf_legacy_loss': False,\n",
       " 'pruned_heads': {},\n",
       " 'tie_word_embeddings': True,\n",
       " 'chunk_size_feed_forward': 0,\n",
       " 'is_encoder_decoder': False,\n",
       " 'is_decoder': False,\n",
       " 'cross_attention_hidden_size': None,\n",
       " 'add_cross_attention': False,\n",
       " 'tie_encoder_decoder': False,\n",
       " 'max_length': 20,\n",
       " 'min_length': 0,\n",
       " 'do_sample': False,\n",
       " 'early_stopping': False,\n",
       " 'num_beams': 1,\n",
       " 'num_beam_groups': 1,\n",
       " 'diversity_penalty': 0.0,\n",
       " 'temperature': 1.0,\n",
       " 'top_k': 50,\n",
       " 'top_p': 1.0,\n",
       " 'typical_p': 1.0,\n",
       " 'repetition_penalty': 1.0,\n",
       " 'length_penalty': 1.0,\n",
       " 'no_repeat_ngram_size': 0,\n",
       " 'encoder_no_repeat_ngram_size': 0,\n",
       " 'bad_words_ids': None,\n",
       " 'num_return_sequences': 1,\n",
       " 'output_scores': False,\n",
       " 'return_dict_in_generate': False,\n",
       " 'forced_bos_token_id': None,\n",
       " 'forced_eos_token_id': None,\n",
       " 'remove_invalid_values': False,\n",
       " 'exponential_decay_length_penalty': None,\n",
       " 'suppress_tokens': None,\n",
       " 'begin_suppress_tokens': None,\n",
       " 'architectures': ['ConvNextV2ForImageClassification'],\n",
       " 'finetuning_task': None,\n",
       " 'tokenizer_class': None,\n",
       " 'prefix': None,\n",
       " 'bos_token_id': None,\n",
       " 'pad_token_id': None,\n",
       " 'eos_token_id': None,\n",
       " 'sep_token_id': None,\n",
       " 'decoder_start_token_id': None,\n",
       " 'task_specific_params': None,\n",
       " 'problem_type': None,\n",
       " '_name_or_path': 'facebook/convnextv2-atto-1k-224',\n",
       " 'transformers_version': '4.40.0.dev0',\n",
       " 'model_type': 'convnextv2',\n",
       " 'stage_names': ['stem', 'stage1', 'stage2', 'stage3', 'stage4'],\n",
       " 'num_channels': 3,\n",
       " 'patch_size': 4,\n",
       " 'num_stages': 4,\n",
       " 'hidden_sizes': [40, 80, 160, 320],\n",
       " 'depths': [2, 2, 6, 2],\n",
       " 'hidden_act': 'gelu',\n",
       " 'initializer_range': 0.02,\n",
       " 'layer_norm_eps': 1e-12,\n",
       " 'drop_path_rate': 0.0,\n",
       " 'image_size': 224,\n",
       " 'out_features': ['stage4'],\n",
       " 'out_indices': [4]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e1da0-ba62-40d7-93a2-4807b7aaf3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana-4.0.58-py3-ml",
   "language": "python",
   "name": "ana-4.0.58-py3-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
