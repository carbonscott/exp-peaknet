# Hydra Configuration Directory Structure

This directory contains configuration files for the project's job launching system. There are **two systems** in use:

## ğŸ†• **NEW: Unified Multi-Facility Launcher** (Recommended)

Use `launch_unified.py` for new projects. It supports all HPC facilities automatically.

### Directory Structure:
```
hydra_config/
â”œâ”€â”€ templates/              # Job script templates for each facility
â”‚   â”œâ”€â”€ s3df.sbatch        # SLAC S3DF (SLURM)
â”‚   â”œâ”€â”€ nersc.sbatch       # NERSC Perlmutter (SLURM)
â”‚   â””â”€â”€ summit.bsub        # ORNL Summit (LSF)
â”‚
â”œâ”€â”€ scheduler_configs/      # Facility-specific settings
â”‚   â”œâ”€â”€ s3df.yaml          # SLAC account, partition, launcher command
â”‚   â”œâ”€â”€ nersc.yaml         # NERSC account, QoS, conda environment
â”‚   â””â”€â”€ summit.yaml        # ORNL project, resource allocation
â”‚
â”œâ”€â”€ resource_configs/       # Compute resource specifications
â”‚   â”œâ”€â”€ base.yaml          # Default: 12hr, 10 GPUs, ada partition
â”‚   â””â”€â”€ hiera.yaml         # Hiera training: 48hr, 10 GPUs, specialized config
â”‚
â”œâ”€â”€ train_config/          # Training configurations
â”‚   â”œâ”€â”€ base.yaml          # Standard training parameters
â”‚   â””â”€â”€ hiera.yaml         # Hiera model architecture & training settings
â”‚
â””â”€â”€ distill_config/        # Knowledge distillation configurations
    â””â”€â”€ base.yaml          # Distillation parameters
```

### Usage:
```bash
# Generate job scripts for ALL facilities
python launch_unified.py job=my-job resource_config=hiera train_config=hiera

# Auto-submit to specific facility  
python launch_unified.py job=my-job auto_submit=true target_facility=s3df

# Then submit the appropriate script for your current facility:
sbatch experiments/jobs/my-job.s3df.sbatch      # SLAC S3DF
sbatch experiments/jobs/my-job.nersc.sbatch     # NERSC
bsub experiments/jobs/my-job.summit.bsub        # ORNL Summit
```

### Benefits:
- âœ… **Future-proof**: Just add new template files for new facilities
- âœ… **No facility detection**: Generate all scripts, pick what works
- âœ… **Clear separation**: Resource specs vs facility-specific settings
- âœ… **Smart naming**: `<job>.<facility>.<scheduler>` format

---

## ğŸ”§ **LEGACY: Facility-Specific Launchers** (Backward Compatibility)

âš ï¸ **DEPRECATED**: These are kept for backward compatibility with existing scripts.

### Directory Structure:
```
hydra_config/
â”œâ”€â”€ bsub_config/           # DEPRECATED: LSF/ORNL Summit configs
â”‚   â”œâ”€â”€ base.yaml         # ğŸ”§ Legacy LSF settings
â”‚   â””â”€â”€ template.bsub     # ğŸ”§ Legacy LSF job template
â”‚
â””â”€â”€ sbatch_config/         # DEPRECATED: SLURM configs  
    â”œâ”€â”€ base.yaml         # ğŸ”§ Legacy SLURM settings
    â”œâ”€â”€ hiera.yaml        # ğŸ”§ Legacy Hiera SLURM settings
    â”œâ”€â”€ template.sbatch   # ğŸ”§ Legacy S3DF SLURM template
    â””â”€â”€ template.nersc.sbatch # ğŸ”§ Legacy NERSC SLURM template
```

### Legacy Launchers (still work, but deprecated):
- `launch_job.py` - LSF/Summit launcher
- `launch_sbatch_job.py` - SLURM/S3DF launcher  
- `launch_job.distill.py` - Distillation launcher
- `launch_job.slurm.py` - Generic SLURM launcher

---

## ğŸš€ **Migration Guide**

### For New Users:
**Use the unified launcher!** It's simpler and works everywhere:
```bash
python launch_unified.py job=my-job train_config=hiera resource_config=hiera
```

### For Existing Users:
Your old scripts still work, but consider migrating:

**Old way:**
```bash
python launch_sbatch_job.py job=my-job sbatch_config=hiera train_config=hiera
```

**New way:**
```bash  
python launch_unified.py job=my-job resource_config=hiera train_config=hiera
```

### Key Changes:
- `sbatch_config=hiera` â†’ `resource_config=hiera` (clearer naming)
- Single launcher for all facilities vs facility-specific launchers
- Job scripts generated for all facilities automatically

---

## ğŸ“‚ **Configuration Details**

### Resource Configs (`resource_configs/`)
Define **compute requirements** (independent of facility):
- Walltime, number of GPUs, memory
- Training script, batch size
- Model architecture parameters

### Scheduler Configs (`scheduler_configs/`)  
Define **facility-specific settings**:
- Account/project IDs
- Partition/queue names
- Module loads, proxy settings
- Job launcher commands (`mpirun`, `srun`, `jsrun`)

### Templates (`templates/`)
Job script templates with Jinja2 placeholders:
- Scheduler directives (`#SBATCH`, `#BSUB`)
- Environment setup
- Job execution commands

---

## ğŸ” **Adding New Facilities**

To add support for a new HPC facility:

1. **Create template**: `hydra_config/templates/new_facility.sbatch`
2. **Create scheduler config**: `hydra_config/scheduler_configs/new_facility.yaml`  
3. **Done!** The unified launcher auto-discovers and generates scripts

No code changes needed - just configuration files.

---

## ğŸ†˜ **Troubleshooting**

**Q: My old scripts stopped working**  
A: Legacy scripts are still supported. Check that you're using the correct paths in `base.yaml`.

**Q: How do I know which facility I'm on?**  
A: Generate all scripts, then submit the one that works. The unified launcher makes this easy.

**Q: Can I customize job templates?**  
A: Yes! Edit files in `templates/` or `scheduler_configs/` to customize for your needs.

**Q: How do I add custom resource configurations?**  
A: Create new YAML files in `resource_configs/` and reference them with `resource_config=your_config`.

---

**ğŸ“§ Questions?** Check the launcher source code or ask the maintainers.